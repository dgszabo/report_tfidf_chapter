{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alk-Abello - ANN - 2007.txt\n",
      "Ambu - ANN - 2007.txt\n",
      "Bang & Olufsen - ANN - 2007.txt\n",
      "Brd A & O Johansen - ANN - 2007.txt\n",
      "DFDS - ANN - 2007.txt\n",
      "FirstFarms - ANN - 2007.txt\n",
      "Greentech Energy Systems - ANN - 2007.txt\n",
      "H+H International - ANN - 2007.txt\n",
      "Harboes Bryggeri - ANN - 2007.txt\n",
      "Per Aarsleff Holding - ANN - 2007.txt\n",
      "Rias - ANN - 2007.txt\n",
      "Roblon - ANN - 2007.txt\n",
      "Rockwool International - ANN - 2007.txt\n",
      "Royal UNIBREW - ANN - 2007.txt\n",
      "RTX - ANN - 2007.txt\n",
      "SimCorp - ANN - 2007.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import csv\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize \n",
    "list_of_files = glob.glob('/Users/dgszabo/Dropbox/Dani/ASB-AU archive/Conferences and Courses/2017-09-Non-financial reporting/Reports/Test selection/2007/*.txt')\n",
    "dash = \"-\"\n",
    "slash = \"/\"\n",
    "space = \" \"\n",
    "punctuation = [\".\", \";\", \",\", \"'\", '\"', \"!\", \"’\", \"%\", \":\", \"&\", \"(\", \")\", '\"', \"#\", \"$\", \"'\",\n",
    "               \"*\", \"+\", \"-\", \"/\", \"<\", \"=\", \">\", \"?\", \"@\", \"[\", \"]\", \"\\\\\", \"^\", \"_\", \"`\", \"{\",\n",
    "               \"|\", \"}\", \"~\", '•', \"...\", \"–\", '“', '”']\n",
    "years = [\"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\"]\n",
    "clutter = [\"j+\", \"1\", \"2\", \"also\", \"bang\", \"olufsen\", \"dfds\", \"simcorp\", \"gabriel\", \"jyske\", \n",
    "           \"genmab\", \"per\", \"'s\", \"rockwool\", \"a/s\", \"\\uf0b7\", \"firstfarms\", \"royal\", \"unibrew\", \n",
    "           \"one\", \"eurosearch\", \"\\x9a\\x01\", \"within\", \"including\", \"alk\", \"arkil\", \"0\", \"3\",\n",
    "           \"kvistgård\", \"harboe\", \"s\\x00\", \"2009/10\", \"4\", \"10\", \"--\", \"∙∙\", \"page\", \"6\", \"5\",\n",
    "           \"2014/15\", \"zealand\", \"matas\", \"h+h\", \"sydbank\", \"2013/14\", \"2017\", \"ion\", \"vestjyskbank\",\n",
    "           \"bavarian\", \"neurosearch\"]\n",
    "data_dic = {}\n",
    "\n",
    "for file_name in list_of_files:\n",
    "    fin = file_name.rfind(dash[0])\n",
    "    fine = file_name.rfind(slash[0])\n",
    "    \n",
    "    data_dic[\"Company\"] = file_name[fine+1:fin-7]\n",
    "    data_dic[\"Report type\"] = file_name[fin-4:fin-1]\n",
    "    data_dic[\"Year\"] = file_name[fin+2:fin+6]\n",
    "    \n",
    "    with open(file_name) as file:\n",
    "        testtext = file.read()\n",
    "        text_tokens = word_tokenize(testtext)\n",
    "        text_tokens_lc = [word.lower() for word in text_tokens]\n",
    "        text_tokens_clean1 = [word for word in text_tokens_lc if word not in stopwords.words('english')]\n",
    "        text_tokens_clean2 = [word for word in text_tokens_clean1 if word not in punctuation]\n",
    "        text_tokens_clean3 = [word for word in text_tokens_clean2 if word not in years]\n",
    "        text_tokens_clean4 = [word for word in text_tokens_clean3 if word not in clutter]\n",
    "        data_dic[\"Body\"] = space.join(text_tokens_clean4)\n",
    "    csv_name = file_name[fine+1:fin+6]+'.csv'\n",
    "    with open(csv_name, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(data_dic.keys())[0]\n",
    "        writer.writerow(data_dic.values())[1]\n",
    "\n",
    "    print (file_name[fine+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-11e431373ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Company\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Reprt type\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Year\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Body\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dgszabo/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                          copy=False)\n\u001b[1;32m    353\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataFrame constructor not properly called!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_all = pd.DataFrame({\"Company\",\"Reprt type\",\"Year\",\"Body\"})\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in multiple text file\n",
    "import glob\n",
    "list_of_files = glob.glob('/Users/dgszabo/Dropbox/Dani/ASB-AU archive/Conferences and Courses/2017-09-Non-financial reporting/Reports/Test selection/2007/*.txt')\n",
    "\n",
    "#create all_tokens list\n",
    "data_dic = {}\n",
    "for file_name in list_of_files:\n",
    "    data_dic[\"Company\"] = \n",
    "    data_dic[\"Report type\"] = \n",
    "    data_dic[\"Year\"] = \n",
    "    with open(file_name) as file:\n",
    "        testtext = file.read()\n",
    "        data_dic[\"body\"] = testtext\n",
    "print(data_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a-b-c\n"
     ]
    }
   ],
   "source": [
    "s = \"-\"\n",
    "seq = (\"a\", \"b\", \"c\") # This is sequence of strings.\n",
    "print (s.join( seq ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas\n",
    "import pandas as pd\n",
    "\n",
    "#import data frame\n",
    "df = pd.read_csv(\"/Users/dgszabo/Dropbox/Dani/ASB-AU archive/Conferences and Courses/2017-09-Non-financial reporting/Reports/Test selection/Summary_table.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 58)\t1\n",
      "  (1, 55)\t1\n",
      "  (2, 57)\t1\n",
      "  (3, 27)\t1\n",
      "  (4, 76)\t1\n",
      "  (5, 138)\t1\n",
      "  (6, 31)\t1\n",
      "  (7, 114)\t1\n",
      "  (8, 85)\t1\n",
      "  (9, 139)\t1\n",
      "  (10, 191)\t1\n",
      "  (11, 44)\t1\n",
      "  (12, 186)\t1\n",
      "  (13, 12)\t1\n",
      "  (14, 4)\t1\n",
      "  (15, 20)\t1\n",
      "  (16, 23)\t1\n",
      "  (17, 49)\t1\n",
      "  (18, 151)\t1\n",
      "  (19, 198)\t1\n",
      "  (20, 110)\t1\n",
      "  (21, 120)\t1\n",
      "  (22, 21)\t1\n",
      "  (23, 52)\t1\n",
      "  (24, 196)\t1\n",
      "  :\t:\n",
      "  (175, 39)\t1\n",
      "  (176, 192)\t1\n",
      "  (177, 188)\t1\n",
      "  (178, 59)\t1\n",
      "  (179, 99)\t1\n",
      "  (180, 22)\t1\n",
      "  (181, 122)\t1\n",
      "  (182, 47)\t1\n",
      "  (183, 70)\t1\n",
      "  (184, 195)\t1\n",
      "  (185, 112)\t1\n",
      "  (186, 136)\t1\n",
      "  (187, 93)\t1\n",
      "  (188, 126)\t1\n",
      "  (189, 178)\t1\n",
      "  (190, 32)\t1\n",
      "  (191, 125)\t1\n",
      "  (192, 68)\t1\n",
      "  (193, 28)\t1\n",
      "  (194, 35)\t1\n",
      "  (194, 10)\t1\n",
      "  (195, 106)\t1\n",
      "  (196, 160)\t1\n",
      "  (197, 161)\t1\n",
      "  (198, 33)\t1\n"
     ]
    }
   ],
   "source": [
    "#import the function CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvec = CountVectorizer()\n",
    "\n",
    "sklearn_dtm = CountVectorizer().fit_transform(df)\n",
    "print(sklearn_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
