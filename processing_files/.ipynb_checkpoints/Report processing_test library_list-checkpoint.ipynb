{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87793\n"
     ]
    }
   ],
   "source": [
    "#read in multiple text file\n",
    "import glob\n",
    "list_of_files = glob.glob('/Users/dgszabo/Dropbox/Dani/ASB-AU archive/Conferences and Courses/2017-09-Non-financial reporting/Reports/Test selection/2016/*.txt')\n",
    "#import to tokenize immediately\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "#create all_tokens list\n",
    "all_tokens = []\n",
    "for file_name in list_of_files:\n",
    "    with open(file_name) as file:\n",
    "        testtext = file.read()\n",
    "        text_tokens = word_tokenize(testtext)\n",
    "        all_tokens.extend(text_tokens)\n",
    "print(len(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create lowercase\n",
    "all_tokens_lc = [word.lower() for word in all_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean stopwords\n",
    "from nltk.corpus import stopwords\n",
    "all_tokens_clean1 = [word for word in all_tokens_lc if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get rid of punctuations\n",
    "punctuation = [\".\", \";\", \",\", \"'\", '\"', \"!\", \"’\", \"%\", \":\", \"&\", \"(\", \")\", '\"', \"#\", \"$\", \"'\",\n",
    "               \"*\", \"+\", \"-\", \"/\", \"<\", \"=\", \">\", \"?\", \"@\", \"[\", \"]\", \"\\\\\", \"^\", \"_\", \"`\", \"{\",\n",
    "               \"|\", \"}\", \"~\", '•', \"...\", \"–\", '“', '”']\n",
    "\n",
    "all_tokens_clean2 = [word for word in all_tokens_clean1 if word not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get rid of years & other clutter\n",
    "years = [\"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\"]\n",
    "\n",
    "all_tokens_clean3 = [word for word in all_tokens_clean2 if word not in years]\n",
    "\n",
    "clutter = [\"j+\", \"1\", \"2\", \"also\", \"bang\", \"olufsen\", \"dfds\", \"simcorp\", \"gabriel\", \"jyske\", \n",
    "           \"genmab\", \"per\", \"'s\", \"rockwool\", \"a/s\", \"\\uf0b7\", \"firstfarms\", \"royal\", \"unibrew\", \n",
    "           \"one\", \"eurosearch\", \"\\x9a\\x01\", \"within\", \"including\", \"alk\", \"arkil\", \"0\", \"3\",\n",
    "           \"kvistgård\", \"harboe\", \"s\\x00\", \"2009/10\", \"4\", \"10\", \"--\", \"∙∙\", \"page\", \"6\", \"5\",\n",
    "           \"2014/15\", \"zealand\", \"matas\", \"h+h\", \"sydbank\", \"2013/14\", \"2017\", \"ion\", \"vestjyskbank\",\n",
    "           \"bavarian\", \"neurosearch\"]\n",
    "\n",
    "all_tokens_clean4 = [word for word in all_tokens_clean3 if word not in clutter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#word frequencies\n",
    "word_frequency = nltk.FreqDist(all_tokens_clean4)\n",
    "\n",
    "#Print out the most common 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#writing dictionary\n",
    "test_list = word_frequency.most_common(100)\n",
    "\n",
    "keys_list = []\n",
    "for element in test_list:\n",
    "    keys_list.append(element[0])\n",
    "print(len(keys_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    }
   ],
   "source": [
    "for variable in keys_list:\n",
    "    if variable not in full_key_list:\n",
    "        full_key_list.append(variable)\n",
    "print (len(full_key_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create csv file\n",
    "import csv\n",
    "with open('full_list.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(full_key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
